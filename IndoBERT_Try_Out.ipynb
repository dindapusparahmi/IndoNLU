{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMB0cDGt/nT2R6HlSwOEZxI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "799fd0f0eb1a4207aedd079e84b5a2c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b568acc7f3a04bd89efa4b7fc8d8d13c",
              "IPY_MODEL_6a3cf3451820490599729e1968770b2c",
              "IPY_MODEL_0333e219272e4ba1ba5bb7eb634984e5"
            ],
            "layout": "IPY_MODEL_2b5a71da21994b17a038ccfdd5e29919"
          }
        },
        "b568acc7f3a04bd89efa4b7fc8d8d13c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_134bf66d24cf4c2bbb454b49bc7412d4",
            "placeholder": "​",
            "style": "IPY_MODEL_358108e070a846148c5bd0a6fd39970c",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "6a3cf3451820490599729e1968770b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df95e012edb74edfbbc9fb72031eb333",
            "max": 229167,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32bfc54bca234ecfa6a588204e3aa9fa",
            "value": 229167
          }
        },
        "0333e219272e4ba1ba5bb7eb634984e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_187c33ca8f3043e1aac7cfcb14497451",
            "placeholder": "​",
            "style": "IPY_MODEL_b4fab644f9dd4f15a8867bf50817c1b0",
            "value": " 229k/229k [00:00&lt;00:00, 1.51MB/s]"
          }
        },
        "2b5a71da21994b17a038ccfdd5e29919": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "134bf66d24cf4c2bbb454b49bc7412d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "358108e070a846148c5bd0a6fd39970c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df95e012edb74edfbbc9fb72031eb333": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32bfc54bca234ecfa6a588204e3aa9fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "187c33ca8f3043e1aac7cfcb14497451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4fab644f9dd4f15a8867bf50817c1b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0125bc7e73d43d99ea02af0b578e71f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_355cef3bf8024dc78af8bf880615c2b1",
              "IPY_MODEL_63bb26e30df84a8198178496c1d66190",
              "IPY_MODEL_7252beb1e2544a4ea75ded38aa4432b9"
            ],
            "layout": "IPY_MODEL_4a03d65c51ae4cbeb67f59b955cd1e5e"
          }
        },
        "355cef3bf8024dc78af8bf880615c2b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ffd8f8237bd472296cdf318c9cf8dae",
            "placeholder": "​",
            "style": "IPY_MODEL_66a802fffbb94e71a8755b43ed94e80b",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "63bb26e30df84a8198178496c1d66190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1205e30a4fc44fbda8dcf9ce0826a0ff",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e130028213c4063807c4b7c783bbdaf",
            "value": 112
          }
        },
        "7252beb1e2544a4ea75ded38aa4432b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6800715c3c0492886121d1e39d3c7ce",
            "placeholder": "​",
            "style": "IPY_MODEL_fb483086292a40018619409d8ef6a942",
            "value": " 112/112 [00:00&lt;00:00, 1.87kB/s]"
          }
        },
        "4a03d65c51ae4cbeb67f59b955cd1e5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ffd8f8237bd472296cdf318c9cf8dae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66a802fffbb94e71a8755b43ed94e80b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1205e30a4fc44fbda8dcf9ce0826a0ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e130028213c4063807c4b7c783bbdaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6800715c3c0492886121d1e39d3c7ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb483086292a40018619409d8ef6a942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6b1ecffa1b6482289f24f8e2bca8bad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a3c86ad0bb64556be8a0147f2668b18",
              "IPY_MODEL_0d8b9f5fc8fb48b6b1e880c0edfe7aa4",
              "IPY_MODEL_c02cb03647d4485ba994247d21019598"
            ],
            "layout": "IPY_MODEL_8caee8c009c44a13b323bc374a20fd0d"
          }
        },
        "8a3c86ad0bb64556be8a0147f2668b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b6e0fa5a17b4ad9af6792ef07be3f6a",
            "placeholder": "​",
            "style": "IPY_MODEL_196f2099976247a1b0e1790abf3eaa2e",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "0d8b9f5fc8fb48b6b1e880c0edfe7aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbb1ba12e27d47b18c29c6f0bf2854f3",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_902324c514e24dd5aebfbe9bb355d8c5",
            "value": 2
          }
        },
        "c02cb03647d4485ba994247d21019598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9474a7c6795448c1853a72b5a97b529c",
            "placeholder": "​",
            "style": "IPY_MODEL_9ef6f1d197e541adb2d2f49ec190d113",
            "value": " 2.00/2.00 [00:00&lt;00:00, 46.4B/s]"
          }
        },
        "8caee8c009c44a13b323bc374a20fd0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b6e0fa5a17b4ad9af6792ef07be3f6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "196f2099976247a1b0e1790abf3eaa2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbb1ba12e27d47b18c29c6f0bf2854f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "902324c514e24dd5aebfbe9bb355d8c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9474a7c6795448c1853a72b5a97b529c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ef6f1d197e541adb2d2f49ec190d113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b63cef3dc324dbcabdd7f62e857673d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7150539c68e47258696896b666321d3",
              "IPY_MODEL_c1bd31cf0bf84a70a571dd14fb11d342",
              "IPY_MODEL_76b612caabe5444e8c480ecd63bfec06"
            ],
            "layout": "IPY_MODEL_68c8db8cbe214d82a5b46054a29c03b1"
          }
        },
        "e7150539c68e47258696896b666321d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e3dc1bac81d4d8abd2a452646bbb541",
            "placeholder": "​",
            "style": "IPY_MODEL_7aecfd4f543744d689e4941e71b403f7",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "c1bd31cf0bf84a70a571dd14fb11d342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d846f3168477482688ac12cc0ebd1708",
            "max": 1534,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4af777141aa64074b964a52341ac04fa",
            "value": 1534
          }
        },
        "76b612caabe5444e8c480ecd63bfec06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_029c55e4cdee444fb4eb713d6ab4b8cb",
            "placeholder": "​",
            "style": "IPY_MODEL_eb7419e2157745f3a61f4ca058d2cb02",
            "value": " 1.53k/1.53k [00:00&lt;00:00, 16.5kB/s]"
          }
        },
        "68c8db8cbe214d82a5b46054a29c03b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e3dc1bac81d4d8abd2a452646bbb541": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aecfd4f543744d689e4941e71b403f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d846f3168477482688ac12cc0ebd1708": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4af777141aa64074b964a52341ac04fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "029c55e4cdee444fb4eb713d6ab4b8cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb7419e2157745f3a61f4ca058d2cb02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c98a53c7a8fd47e0940321a19882d4ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62424d970473424a9dfb1952b2194f07",
              "IPY_MODEL_2d9e6040f1104952b315d9987c589969",
              "IPY_MODEL_926ecaf2930543bdbc5a10aa6b8150fc"
            ],
            "layout": "IPY_MODEL_7696de80e5aa4f7383e18ab8312a2149"
          }
        },
        "62424d970473424a9dfb1952b2194f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dac859c90def434694bd22f982aa59e2",
            "placeholder": "​",
            "style": "IPY_MODEL_ba58ea41bfe641e2b5a4aaa39ed52d89",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "2d9e6040f1104952b315d9987c589969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b974691283cd4d28bb6900a563ad6e04",
            "max": 497810400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e17dbb9e67549d78da431cbc2ba9050",
            "value": 497810400
          }
        },
        "926ecaf2930543bdbc5a10aa6b8150fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edf2ea0efed04da79a1aff277ccc77ae",
            "placeholder": "​",
            "style": "IPY_MODEL_daf0d7b50c1c4b4f97fa846fe07c5282",
            "value": " 498M/498M [00:06&lt;00:00, 85.4MB/s]"
          }
        },
        "7696de80e5aa4f7383e18ab8312a2149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dac859c90def434694bd22f982aa59e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba58ea41bfe641e2b5a4aaa39ed52d89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b974691283cd4d28bb6900a563ad6e04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e17dbb9e67549d78da431cbc2ba9050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edf2ea0efed04da79a1aff277ccc77ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daf0d7b50c1c4b4f97fa846fe07c5282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gorgeousbeasty/IndoNLU/blob/master/IndoBERT_Try_Out.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Load Model**\n",
        "https://huggingface.co/models\n",
        "\n",
        "untuk task classification & sequence tagging, gunakan Encoder-only model transformer\n",
        "\n",
        "https://huggingface.co/indobenchmark/indobert-base-p1"
      ],
      "metadata": {
        "id": "J97qRgnkycl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "PclCqEdF38Xq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b938f416-5d37-4f53-f681-f9632e462401"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, BertConfig, BertTokenizer\n",
        "from nltk.tokenize import TweetTokenizer"
      ],
      "metadata": {
        "id": "ptLYpDRh3wdq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install utils\n"
      ],
      "metadata": {
        "id": "JMMC5Q_R4u0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79f2ebd9-2396-4cae-ef2c-8a237c730f2c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting utils\n",
            "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fasttext"
      ],
      "metadata": {
        "id": "pvz2mwmv0HMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b5dfcee-994d-4cf3-a785-fccde553e4ae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fasttext\n",
            "  Using cached fasttext-0.9.2.tar.gz (68 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.8/dist-packages (from fasttext) (2.10.3)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fasttext) (1.22.4)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp38-cp38-linux_x86_64.whl size=4399283 sha256=6ea7e193c4a45ee984dd55cb0780491bfcf6456340c98069a367c8d9e905e514\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/61/2a/c54711a91c418ba06ba195b1d78ff24fcaad8592f2a694ac94\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import fasttext\n",
        "from nltk import word_tokenize"
      ],
      "metadata": {
        "id": "QJp2BWdPzsSX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#clone forked IndoNLU Github\n",
        "!git clone 'https://github.com/dindapusparahmi/IndoNLU/'"
      ],
      "metadata": {
        "id": "KB0eKDFZ3h2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4540a5a2-7d35-459a-b1c1-39d22df04a4d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IndoNLU'...\n",
            "remote: Enumerating objects: 500, done.\u001b[K\n",
            "remote: Counting objects: 100% (184/184), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 500 (delta 115), reused 142 (delta 111), pack-reused 316\u001b[K\n",
            "Receiving objects: 100% (500/500), 9.45 MiB | 17.19 MiB/s, done.\n",
            "Resolving deltas: 100% (235/235), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IndoNLU.utils.forward_fn import forward_sequence_classification\n",
        "from IndoNLU.utils.metrics import document_sentiment_metrics_fn\n",
        "from IndoNLU.utils.data_utils import DocumentSentimentDataset, DocumentSentimentDataLoader"
      ],
      "metadata": {
        "id": "zid5kXbf4bI0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uOrExWIFyBky",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232,
          "referenced_widgets": [
            "799fd0f0eb1a4207aedd079e84b5a2c6",
            "b568acc7f3a04bd89efa4b7fc8d8d13c",
            "6a3cf3451820490599729e1968770b2c",
            "0333e219272e4ba1ba5bb7eb634984e5",
            "2b5a71da21994b17a038ccfdd5e29919",
            "134bf66d24cf4c2bbb454b49bc7412d4",
            "358108e070a846148c5bd0a6fd39970c",
            "df95e012edb74edfbbc9fb72031eb333",
            "32bfc54bca234ecfa6a588204e3aa9fa",
            "187c33ca8f3043e1aac7cfcb14497451",
            "b4fab644f9dd4f15a8867bf50817c1b0",
            "a0125bc7e73d43d99ea02af0b578e71f",
            "355cef3bf8024dc78af8bf880615c2b1",
            "63bb26e30df84a8198178496c1d66190",
            "7252beb1e2544a4ea75ded38aa4432b9",
            "4a03d65c51ae4cbeb67f59b955cd1e5e",
            "8ffd8f8237bd472296cdf318c9cf8dae",
            "66a802fffbb94e71a8755b43ed94e80b",
            "1205e30a4fc44fbda8dcf9ce0826a0ff",
            "6e130028213c4063807c4b7c783bbdaf",
            "a6800715c3c0492886121d1e39d3c7ce",
            "fb483086292a40018619409d8ef6a942",
            "b6b1ecffa1b6482289f24f8e2bca8bad",
            "8a3c86ad0bb64556be8a0147f2668b18",
            "0d8b9f5fc8fb48b6b1e880c0edfe7aa4",
            "c02cb03647d4485ba994247d21019598",
            "8caee8c009c44a13b323bc374a20fd0d",
            "7b6e0fa5a17b4ad9af6792ef07be3f6a",
            "196f2099976247a1b0e1790abf3eaa2e",
            "dbb1ba12e27d47b18c29c6f0bf2854f3",
            "902324c514e24dd5aebfbe9bb355d8c5",
            "9474a7c6795448c1853a72b5a97b529c",
            "9ef6f1d197e541adb2d2f49ec190d113",
            "4b63cef3dc324dbcabdd7f62e857673d",
            "e7150539c68e47258696896b666321d3",
            "c1bd31cf0bf84a70a571dd14fb11d342",
            "76b612caabe5444e8c480ecd63bfec06",
            "68c8db8cbe214d82a5b46054a29c03b1",
            "0e3dc1bac81d4d8abd2a452646bbb541",
            "7aecfd4f543744d689e4941e71b403f7",
            "d846f3168477482688ac12cc0ebd1708",
            "4af777141aa64074b964a52341ac04fa",
            "029c55e4cdee444fb4eb713d6ab4b8cb",
            "eb7419e2157745f3a61f4ca058d2cb02",
            "c98a53c7a8fd47e0940321a19882d4ad",
            "62424d970473424a9dfb1952b2194f07",
            "2d9e6040f1104952b315d9987c589969",
            "926ecaf2930543bdbc5a10aa6b8150fc",
            "7696de80e5aa4f7383e18ab8312a2149",
            "dac859c90def434694bd22f982aa59e2",
            "ba58ea41bfe641e2b5a4aaa39ed52d89",
            "b974691283cd4d28bb6900a563ad6e04",
            "2e17dbb9e67549d78da431cbc2ba9050",
            "edf2ea0efed04da79a1aff277ccc77ae",
            "daf0d7b50c1c4b4f97fa846fe07c5282"
          ]
        },
        "outputId": "a62cab0c-5685-443c-cbc2-bb2f7ff1b3b1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "799fd0f0eb1a4207aedd079e84b5a2c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0125bc7e73d43d99ea02af0b578e71f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6b1ecffa1b6482289f24f8e2bca8bad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b63cef3dc324dbcabdd7f62e857673d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/498M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c98a53c7a8fd47e0940321a19882d4ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load Tokenizer and Config\n",
        "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
        "config = BertConfig.from_pretrained('indobenchmark/indobert-base-p1')\n",
        "config.num_labels = DocumentSentimentDataset.NUM_LABELS\n",
        "\n",
        "# Instantiate model\n",
        "model = BertForSequenceClassification.from_pretrained('indobenchmark/indobert-base-p1', config=config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "Ii-mmv75IFtL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5f42a73-c2cb-4afc-fd18-b5c992bea31e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(50000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "# common functions\n",
        "###\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    \n",
        "def count_param(module, trainable=False):\n",
        "    if trainable:\n",
        "        return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
        "    else:\n",
        "        return sum(p.numel() for p in module.parameters())\n",
        "    \n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def metrics_to_string(metric_dict):\n",
        "    string_list = []\n",
        "    for key, value in metric_dict.items():\n",
        "        string_list.append('{}:{:.2f}'.format(key, value))\n",
        "    return ' '.join(string_list)"
      ],
      "metadata": {
        "id": "N8xLfF3p4XIT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_param(model)"
      ],
      "metadata": {
        "id": "ZeE-VQwzIIOd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94e699c8-e7b4-4f07-9f8d-3525c76c7d7c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124443651"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "set_seed(26022023)"
      ],
      "metadata": {
        "id": "Sbq0ALTs4ap9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_path = '/content/IndoNLU/dataset/smsa_doc-sentiment-prosa/train_preprocess.tsv'\n",
        "valid_dataset_path = '/content/IndoNLU/dataset/smsa_doc-sentiment-prosa/valid_preprocess.tsv'\n",
        "test_dataset_path = '/content/IndoNLU/dataset/smsa_doc-sentiment-prosa/test_preprocess.tsv'"
      ],
      "metadata": {
        "id": "6Ki3Cv4D4tRL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "2EnOXAukKdOx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####\n",
        "# Document Sentiment Prosa\n",
        "#####\n",
        "class DocumentSentimentDataset(Dataset):\n",
        "    # Static constant variable\n",
        "    LABEL2INDEX = {'positive': 0, 'neutral': 1, 'negative': 2}\n",
        "    INDEX2LABEL = {0: 'positive', 1: 'neutral', 2: 'negative'}\n",
        "    NUM_LABELS = 3\n",
        "    \n",
        "    def load_dataset(self, path): \n",
        "        df = pd.read_csv(path, sep='\\t', header=None)\n",
        "        df.columns = ['text','sentiment']\n",
        "        df['sentiment'] = df['sentiment'].apply(lambda lab: self.LABEL2INDEX[lab])\n",
        "        return df\n",
        "    \n",
        "    def __init__(self, dataset_path, tokenizer, no_special_token=False, *args, **kwargs):\n",
        "        self.data = self.load_dataset(dataset_path)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.no_special_token = no_special_token\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        data = self.data.loc[index,:]\n",
        "        text, sentiment = data['text'], data['sentiment']\n",
        "        subwords = self.tokenizer.encode(text, add_special_tokens=not self.no_special_token)\n",
        "        return np.array(subwords), np.array(sentiment), data['text']\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)    \n",
        "        \n",
        "class DocumentSentimentDataLoader(DataLoader):\n",
        "    def __init__(self, max_seq_len=512, *args, **kwargs):\n",
        "        super(DocumentSentimentDataLoader, self).__init__(*args, **kwargs)\n",
        "        self.collate_fn = self._collate_fn\n",
        "        self.max_seq_len = max_seq_len\n",
        "        \n",
        "    def _collate_fn(self, batch):\n",
        "        batch_size = len(batch)\n",
        "        max_seq_len = max(map(lambda x: len(x[0]), batch))\n",
        "        max_seq_len = min(self.max_seq_len, max_seq_len)\n",
        "        \n",
        "        subword_batch = np.zeros((batch_size, max_seq_len), dtype=np.int64)\n",
        "        mask_batch = np.zeros((batch_size, max_seq_len), dtype=np.float32)\n",
        "        sentiment_batch = np.zeros((batch_size, 1), dtype=np.int64)\n",
        "        \n",
        "        seq_list = []\n",
        "        for i, (subwords, sentiment, raw_seq) in enumerate(batch):\n",
        "            subwords = subwords[:max_seq_len]\n",
        "            subword_batch[i,:len(subwords)] = subwords\n",
        "            mask_batch[i,:len(subwords)] = 1\n",
        "            sentiment_batch[i,0] = sentiment\n",
        "            \n",
        "            seq_list.append(raw_seq)\n",
        "            \n",
        "        return subword_batch, mask_batch, sentiment_batch, seq_list\n",
        "\n"
      ],
      "metadata": {
        "id": "8w-4L9ZqKemc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = DocumentSentimentDataset(train_dataset_path, tokenizer, lowercase=True)\n",
        "valid_dataset = DocumentSentimentDataset(valid_dataset_path, tokenizer, lowercase=True)\n",
        "test_dataset = DocumentSentimentDataset(test_dataset_path, tokenizer, lowercase=True, on_bad_lines='skip')\n",
        "\n",
        "train_loader = DocumentSentimentDataLoader(dataset=train_dataset, max_seq_len=512, batch_size=32, num_workers=16, shuffle=True)  \n",
        "valid_loader = DocumentSentimentDataLoader(dataset=valid_dataset, max_seq_len=512, batch_size=32, num_workers=16, shuffle=False)  \n",
        "test_loader = DocumentSentimentDataLoader(dataset=test_dataset, max_seq_len=512, batch_size=32, num_workers=16, shuffle=False)"
      ],
      "metadata": {
        "id": "K1nYlJ0KHR1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d04b69e6-a96a-438f-f291-5e2798d2a336"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2i, i2w = DocumentSentimentDataset.LABEL2INDEX, DocumentSentimentDataset.INDEX2LABEL\n",
        "print(w2i)\n",
        "print(i2w)"
      ],
      "metadata": {
        "id": "Po0PQJuBIzh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8171b22-e04e-42ff-b7ab-34888e4fd9ea"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'positive': 0, 'neutral': 1, 'negative': 2}\n",
            "{0: 'positive', 1: 'neutral', 2: 'negative'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fine Tuning & Evaluation**"
      ],
      "metadata": {
        "id": "npWXO2BAaO1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "sys.path.append('../')\n",
        "os.chdir('../')\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
      ],
      "metadata": {
        "id": "Up1QvtPSanj9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "id": "Ahwz2MgmcIdO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "65d8f28d-0cdc-4686-e308-2331e537e32a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "###\n",
        "# Forward Function\n",
        "###\n",
        "\n",
        "# Forward function for sequence classification\n",
        "def forward_sequence_classification(model, batch_data, i2w, is_test=False, device='cpu', **kwargs):\n",
        "    # Unpack batch data\n",
        "    if len(batch_data) == 3:\n",
        "        (subword_batch, mask_batch, label_batch) = batch_data\n",
        "        token_type_batch = None\n",
        "    elif len(batch_data) == 4:\n",
        "        (subword_batch, mask_batch, token_type_batch, label_batch) = batch_data\n",
        "    \n",
        "    # Prepare input & label\n",
        "    subword_batch = torch.LongTensor(subword_batch)\n",
        "    mask_batch = torch.FloatTensor(mask_batch)\n",
        "    token_type_batch = torch.LongTensor(token_type_batch) if token_type_batch is not None else None\n",
        "    label_batch = torch.LongTensor(label_batch)\n",
        "            \n",
        "    if device == \"cuda\":\n",
        "        subword_batch = subword_batch.cuda()\n",
        "        mask_batch = mask_batch.cuda()\n",
        "        token_type_batch = token_type_batch.cuda() if token_type_batch is not None else None\n",
        "        label_batch = label_batch.cuda()\n",
        "\n",
        "    # Forward model\n",
        "    outputs = model(subword_batch, attention_mask=mask_batch, token_type_ids=token_type_batch, labels=label_batch)\n",
        "    loss, logits = outputs[:2]\n",
        "    \n",
        "    # generate prediction & label list\n",
        "    list_hyp = []\n",
        "    list_label = []\n",
        "    hyp = torch.topk(logits, 1)[1]\n",
        "    for j in range(len(hyp)):\n",
        "        list_hyp.append(i2w[hyp[j].item()])\n",
        "        list_label.append(i2w[label_batch[j][0].item()])\n",
        "        \n",
        "    return loss, list_hyp, list_label\n",
        "\n",
        "# Forward function for word classification\n",
        "def forward_word_classification(model, batch_data, i2w, is_test=False, device='cpu', **kwargs):\n",
        "    # Unpack batch data\n",
        "    if len(batch_data) == 4:\n",
        "        (subword_batch, mask_batch, subword_to_word_indices_batch, label_batch) = batch_data\n",
        "        token_type_batch = None\n",
        "    elif len(batch_data) == 5:\n",
        "        (subword_batch, mask_batch, token_type_batch, subword_to_word_indices_batch, label_batch) = batch_data\n",
        "    \n",
        "    # Prepare input & label\n",
        "    subword_batch = torch.LongTensor(subword_batch)\n",
        "    mask_batch = torch.FloatTensor(mask_batch)\n",
        "    token_type_batch = torch.LongTensor(token_type_batch) if token_type_batch is not None else None\n",
        "    subword_to_word_indices_batch = torch.LongTensor(subword_to_word_indices_batch)\n",
        "    label_batch = torch.LongTensor(label_batch)\n",
        "\n",
        "    if device == \"cuda\":\n",
        "        subword_batch = subword_batch.cuda()\n",
        "        mask_batch = mask_batch.cuda()\n",
        "        token_type_batch = token_type_batch.cuda() if token_type_batch is not None else None\n",
        "        subword_to_word_indices_batch = subword_to_word_indices_batch.cuda()\n",
        "        label_batch = label_batch.cuda()\n",
        "\n",
        "    # Forward model\n",
        "    outputs = model(subword_batch, subword_to_word_indices_batch, attention_mask=mask_batch, token_type_ids=token_type_batch, labels=label_batch)\n",
        "    loss, logits = outputs[:2]\n",
        "    \n",
        "    # generate prediction & label list\n",
        "    list_hyps = []\n",
        "    list_labels = []\n",
        "    hyps_list = torch.topk(logits, k=1, dim=-1)[1].squeeze(dim=-1)\n",
        "    for i in range(len(hyps_list)):\n",
        "        hyps, labels = hyps_list[i].tolist(), label_batch[i].tolist()        \n",
        "        list_hyp, list_label = [], []\n",
        "        for j in range(len(hyps)):\n",
        "            if labels[j] == -100:\n",
        "                break\n",
        "            else:\n",
        "                list_hyp.append(i2w[hyps[j]])\n",
        "                list_label.append(i2w[labels[j]])\n",
        "        list_hyps.append(list_hyp)\n",
        "        list_labels.append(list_label)\n",
        "        \n",
        "    return loss, list_hyps, list_labels\n",
        "\n",
        "# Forward function for sequence multilabel classification\n",
        "def forward_sequence_multi_classification(model, batch_data, i2w, is_test=False, device='cpu', **kwargs):\n",
        "    # Unpack batch data\n",
        "    if len(batch_data) == 3:\n",
        "        (subword_batch, mask_batch, label_batch) = batch_data\n",
        "        token_type_batch = None\n",
        "    elif len(batch_data) == 4:\n",
        "        (subword_batch, mask_batch, token_type_batch, label_batch) = batch_data\n",
        "    \n",
        "    # Prepare input & label\n",
        "    subword_batch = torch.LongTensor(subword_batch)\n",
        "    mask_batch = torch.FloatTensor(mask_batch)\n",
        "    token_type_batch = torch.LongTensor(token_type_batch) if token_type_batch is not None else None\n",
        "    label_batch = torch.LongTensor(label_batch)\n",
        "            \n",
        "    if device == \"cuda\":\n",
        "        subword_batch = subword_batch.cuda()\n",
        "        mask_batch = mask_batch.cuda()\n",
        "        token_type_batch = token_type_batch.cuda() if token_type_batch is not None else None\n",
        "        label_batch = label_batch.cuda()\n",
        "\n",
        "    # Forward model\n",
        "    outputs = model(subword_batch, attention_mask=mask_batch, token_type_ids=token_type_batch, labels=label_batch)\n",
        "    loss, logits = outputs[:2] # logits list<tensor(bs, num_label)> ~ list of batch prediction per class \n",
        "    import torch\n",
        "\n",
        "###\n",
        "# Forward Function\n",
        "###\n",
        "\n",
        "# Forward function for sequence classification\n",
        "def forward_sequence_classification(model, batch_data, i2w, is_test=False, device='cpu', **kwargs):\n",
        "    # Unpack batch data\n",
        "    if len(batch_data) == 3:\n",
        "        (subword_batch, mask_batch, label_batch) = batch_data\n",
        "        token_type_batch = None\n",
        "    elif len(batch_data) == 4:\n",
        "        (subword_batch, mask_batch, token_type_batch, label_batch) = batch_data\n",
        "    \n",
        "    # Prepare input & label\n",
        "    subword_batch = torch.LongTensor(subword_batch)\n",
        "    mask_batch = torch.FloatTensor(mask_batch)\n",
        "    token_type_batch = torch.LongTensor(token_type_batch) if token_type_batch is not None else None\n",
        "    label_batch = torch.LongTensor(label_batch)\n",
        "            \n",
        "    if device == \"cuda\":\n",
        "        subword_batch = subword_batch.cuda()\n",
        "        mask_batch = mask_batch.cuda()\n",
        "        token_type_batch = token_type_batch.cuda() if token_type_batch is not None else None\n",
        "        label_batch = label_batch.cuda()\n",
        "\n",
        "    # Forward model\n",
        "    outputs = model(subword_batch, attention_mask=mask_batch, token_type_ids=token_type_batch, labels=label_batch)\n",
        "    loss, logits = outputs[:2]\n",
        "    \n",
        "    # generate prediction & label list\n",
        "    list_hyp = []\n",
        "    list_label = []\n",
        "    hyp = torch.topk(logits, 1)[1]\n",
        "    for j in range(len(hyp)):\n",
        "        list_hyp.append(i2w[hyp[j].item()])\n",
        "        list_label.append(i2w[label_batch[j][0].item()])\n",
        "        \n",
        "    return loss, list_hyp, list_label\n",
        "\n",
        "# Forward function for word classification\n",
        "def forward_word_classification(model, batch_data, i2w, is_test=False, device='cpu', **kwargs):\n",
        "    # Unpack batch data\n",
        "    if len(batch_data) == 4:\n",
        "        (subword_batch, mask_batch, subword_to_word_indices_batch, label_batch) = batch_data\n",
        "        token_type_batch = None\n",
        "    elif len(batch_data) == 5:\n",
        "        (subword_batch, mask_batch, token_type_batch, subword_to_word_indices_batch, label_batch) = batch_data\n",
        "    \n",
        "    # Prepare input & label\n",
        "    subword_batch = torch.LongTensor(subword_batch)\n",
        "    mask_batch = torch.FloatTensor(mask_batch)\n",
        "    token_type_batch = torch.LongTensor(token_type_batch) if token_type_batch is not None else None\n",
        "    subword_to_word_indices_batch = torch.LongTensor(subword_to_word_indices_batch)\n",
        "    label_batch = torch.LongTensor(label_batch)\n",
        "\n",
        "    if device == \"cuda\":\n",
        "        subword_batch = subword_batch.cuda()\n",
        "        mask_batch = mask_batch.cuda()\n",
        "        token_type_batch = token_type_batch.cuda() if token_type_batch is not None else None\n",
        "        subword_to_word_indices_batch = subword_to_word_indices_batch.cuda()\n",
        "        label_batch = label_batch.cuda()\n",
        "\n",
        "    # Forward model\n",
        "    outputs = model(subword_batch, subword_to_word_indices_batch, attention_mask=mask_batch, token_type_ids=token_type_batch, labels=label_batch)\n",
        "    loss, logits = outputs[:2]\n",
        "    \n",
        "    # generate prediction & label list\n",
        "    list_hyps = []\n",
        "    list_labels = []\n",
        "    hyps_list = torch.topk(logits, k=1, dim=-1)[1].squeeze(dim=-1)\n",
        "    for i in range(len(hyps_list)):\n",
        "        hyps, labels = hyps_list[i].tolist(), label_batch[i].tolist()        \n",
        "        list_hyp, list_label = [], []\n",
        "        for j in range(len(hyps)):\n",
        "            if labels[j] == -100:\n",
        "                break\n",
        "            else:\n",
        "                list_hyp.append(i2w[hyps[j]])\n",
        "                list_label.append(i2w[labels[j]])\n",
        "        list_hyps.append(list_hyp)\n",
        "        list_labels.append(list_label)\n",
        "        \n",
        "    return loss, list_hyps, list_labels\n",
        "\n",
        "# Forward function for sequence multilabel classification\n",
        "def forward_sequence_multi_classification(model, batch_data, i2w, is_test=False, device='cpu', **kwargs):\n",
        "    # Unpack batch data\n",
        "    if len(batch_data) == 3:\n",
        "        (subword_batch, mask_batch, label_batch) = batch_data\n",
        "        token_type_batch = None\n",
        "    elif len(batch_data) == 4:\n",
        "        (subword_batch, mask_batch, token_type_batch, label_batch) = batch_data\n",
        "    \n",
        "    # Prepare input & label\n",
        "    subword_batch = torch.LongTensor(subword_batch)\n",
        "    mask_batch = torch.FloatTensor(mask_batch)\n",
        "    token_type_batch = torch.LongTensor(token_type_batch) if token_type_batch is not None else None\n",
        "    label_batch = torch.LongTensor(label_batch)\n",
        "            \n",
        "    if device == \"cuda\":\n",
        "        subword_batch = subword_batch.cuda()\n",
        "        mask_batch = mask_batch.cuda()\n",
        "        token_type_batch = token_type_batch.cuda() if token_type_batch is not None else None\n",
        "        label_batch = label_batch.cuda()\n",
        "\n",
        "    # Forward model\n",
        "    outputs = model(subword_batch, attention_mask=mask_batch, token_type_ids=token_type_batch, labels=label_batch)\n",
        "    loss, logits = outputs[:2] # logits list<tensor(bs, num_label)> ~ list of batch prediction per class \n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "6-2ZGacYc1_w"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=5e-6)\n"
      ],
      "metadata": {
        "id": "Cv8k05xXaOEo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.cuda()"
      ],
      "metadata": {
        "id": "DrihakdpdEbn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "P58_T1W5ehxi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "102bab0c-b0f5-4d0b-f262-8f5990d181d7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "or9iLHDWHn2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d4bc441-9c48-4f12-a8d0-bf0c69e845ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "(Epoch 1) TRAIN LOSS:0.3082 LR:0.00000500: 100%|██████████| 344/344 [02:38<00:00,  2.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 1) TRAIN LOSS:0.3082 ACC:0.88 F1:0.84 REC:0.81 PRE:0.87 LR:0.00000500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/40 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "VALID LOSS:0.1809 ACC:0.93 F1:0.90 REC:0.90 PRE:0.91: 100%|██████████| 40/40 [00:08<00:00,  4.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 1) VALID LOSS:0.1809 ACC:0.93 F1:0.90 REC:0.90 PRE:0.91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "(Epoch 2) TRAIN LOSS:0.1408 LR:0.00000500: 100%|██████████| 344/344 [02:41<00:00,  2.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 2) TRAIN LOSS:0.1408 ACC:0.95 F1:0.94 REC:0.94 PRE:0.94 LR:0.00000500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/40 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "VALID LOSS:0.1649 ACC:0.94 F1:0.92 REC:0.91 PRE:0.92: 100%|██████████| 40/40 [00:07<00:00,  5.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 2) VALID LOSS:0.1649 ACC:0.94 F1:0.92 REC:0.91 PRE:0.92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "(Epoch 3) TRAIN LOSS:0.0992 LR:0.00000500: 100%|██████████| 344/344 [02:42<00:00,  2.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 3) TRAIN LOSS:0.0992 ACC:0.97 F1:0.96 REC:0.96 PRE:0.97 LR:0.00000500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/40 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "VALID LOSS:0.1862 ACC:0.93 F1:0.91 REC:0.90 PRE:0.92: 100%|██████████| 40/40 [00:09<00:00,  4.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 3) VALID LOSS:0.1862 ACC:0.93 F1:0.91 REC:0.90 PRE:0.92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "(Epoch 4) TRAIN LOSS:0.0623 LR:0.00000500: 100%|██████████| 344/344 [02:41<00:00,  2.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 4) TRAIN LOSS:0.0623 ACC:0.98 F1:0.98 REC:0.97 PRE:0.98 LR:0.00000500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/40 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "VALID LOSS:0.2028 ACC:0.93 F1:0.91 REC:0.90 PRE:0.92: 100%|██████████| 40/40 [00:08<00:00,  4.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 4) VALID LOSS:0.2028 ACC:0.93 F1:0.91 REC:0.90 PRE:0.92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/344 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "(Epoch 5) TRAIN LOSS:0.0400 LR:0.00000500: 100%|██████████| 344/344 [02:42<00:00,  2.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 5) TRAIN LOSS:0.0400 ACC:0.99 F1:0.99 REC:0.98 PRE:0.99 LR:0.00000500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/40 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "VALID LOSS:0.2035 ACC:0.94 F1:0.91 REC:0.91 PRE:0.92: 100%|██████████| 40/40 [00:08<00:00,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Epoch 5) VALID LOSS:0.2035 ACC:0.94 F1:0.91 REC:0.91 PRE:0.92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "n_epochs = 5\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    torch.set_grad_enabled(True)\n",
        " \n",
        "    total_train_loss = 0\n",
        "    list_hyp, list_label = [], []\n",
        "\n",
        "    train_pbar = tqdm(train_loader, leave=True, total=len(train_loader))\n",
        "    for i, batch_data in enumerate(train_pbar):\n",
        "        # Forward model\n",
        "        loss, batch_hyp, batch_label = forward_sequence_classification(model, batch_data[:-1], i2w=i2w, device='cuda')\n",
        "\n",
        "        # Update model\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        tr_loss = loss.item()\n",
        "        total_train_loss = total_train_loss + tr_loss\n",
        "\n",
        "        # Calculate metrics\n",
        "        list_hyp += batch_hyp\n",
        "        list_label += batch_label\n",
        "\n",
        "        train_pbar.set_description(\"(Epoch {}) TRAIN LOSS:{:.4f} LR:{:.8f}\".format((epoch+1),\n",
        "            total_train_loss/(i+1), get_lr(optimizer)))\n",
        "\n",
        "    # Calculate train metric\n",
        "    metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
        "    print(\"(Epoch {}) TRAIN LOSS:{:.4f} {} LR:{:.8f}\".format((epoch+1),\n",
        "        total_train_loss/(i+1), metrics_to_string(metrics), get_lr(optimizer)))\n",
        "\n",
        "    # Evaluate on validation\n",
        "    model.eval()\n",
        "    torch.set_grad_enabled(False)\n",
        "    \n",
        "    total_loss, total_correct, total_labels = 0, 0, 0\n",
        "    list_hyp, list_label = [], []\n",
        "\n",
        "    pbar = tqdm(valid_loader, leave=True, total=len(valid_loader))\n",
        "    for i, batch_data in enumerate(pbar):\n",
        "        batch_seq = batch_data[-1]        \n",
        "        loss, batch_hyp, batch_label = forward_sequence_classification(model, batch_data[:-1], i2w=i2w, device='cuda')\n",
        "        \n",
        "        # Calculate total loss\n",
        "        valid_loss = loss.item()\n",
        "        total_loss = total_loss + valid_loss\n",
        "\n",
        "        # Calculate evaluation metrics\n",
        "        list_hyp += batch_hyp\n",
        "        list_label += batch_label\n",
        "        metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
        "\n",
        "        pbar.set_description(\"VALID LOSS:{:.4f} {}\".format(total_loss/(i+1), metrics_to_string(metrics)))\n",
        "        \n",
        "    metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
        "    print(\"(Epoch {}) VALID LOSS:{:.4f} {}\".format((epoch+1),\n",
        "        total_loss/(i+1), metrics_to_string(metrics)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test\n",
        "model.eval()\n",
        "torch.set_grad_enabled(False)\n",
        "\n",
        "total_loss, total_correct, total_labels = 0, 0, 0\n",
        "list_hyp, list_label = [], []\n",
        "\n",
        "pbar = tqdm(test_loader, leave=True, total=len(test_loader))\n",
        "for i, batch_data in enumerate(pbar):\n",
        "    _, batch_hyp, batch_label = forward_sequence_classification(model, batch_data[:-1], i2w=i2w, device='cuda')\n",
        "    list_hyp += batch_hyp\n",
        "    list_label += batch_label\n",
        "metrics = document_sentiment_metrics_fn(list_hyp, list_label)\n",
        "print(\"TEST Metrics | {}\".format(metrics_to_string(metrics)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuSW1jWI6_AC",
        "outputId": "597f7581-2afb-4248-96f2-cb84afcb738a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/16 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100%|██████████| 16/16 [00:03<00:00,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST Metrics | ACC:0.92 F1:0.90 REC:0.89 PRE:0.92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Fine Tuned Model on Sample Sentence**\n",
        "\n",
        "Mencoba fine tuned model pada frasa berita yang diekstraksi\n",
        "- 2 dari 3 frasa dengan label up diklasifikasi positive. 1 diklasifikasi negatif (53,81%)\n",
        "- 2dari 3 frasa dengan label down diklasifikasi negatif.\n",
        "- narasi berita dengan ukuran asli terlalu besar sehingga menhasilkan error"
      ],
      "metadata": {
        "id": "e4p_QC6AO5av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'data penjualan Gaikindo saat kenaikan BBM yang terjadi di masa lalu. Menurut data yang disampaikan, penjualan BBM naik malah bikin penjualan naik.\"Tahun 2003 pernah ada kenaikan bahan bakar, 2004 naik lagi harga bbmnya. Kemudian disusul tahun 2005. Namun di sepanjang 3 tahun itu kondisinya menarik. Melihat penjualan grafik 2003, 2004, 2005 itu naik, dari ke 354 (ribu) ke 534 (ribu),\" ungkap Kukuh saat diskusi virtual bersama Forum Wartawan Otomotif, Kamis (15/9/2022).\"Dalam kurun waktu itu kenaikan bahan bakar tidak berpengaruh ke penjualan kendaraan bermotor,\" jelas dia.Lebih lanjut Kukuh juga membagikan data penjualan saat BBM mengalami kenaikan pada tahun 2012 dan 2013. Pola kenaikan penjualan juga terjadi dalam kurun waktu tersebut. Pada 2012, Gaikindo mencatat penjualan mencapai 894 ribu unit, dan setahun berikutnya naik jadi 1,16 juta unit.\"Kejadian ini berulang lagi di tahun 2012, 2013, di mana ada kenaikan bahan bakar. Saat itu pun kalau kita lihat pertumbuhan ekonomi bagus di 6,2 (persen) di 2012, dan sekitar 5,78 (persen) di 2013. Dua tahun itu penjualan kendaraan bermotor juga naik walaupun ada kenaikan bahan bakar,\" terang dia.\"Kita harapkan dari data-data sejarah seperti itu, kita harapkan kenaikan kali inipun tidak berpengaruh terhadap penjualan kendaraan bermotor,\"'\n",
        "subwords = tokenizer.encode(text)\n",
        "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
        "\n",
        "logits = model(subwords)[0]\n",
        "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
        "\n",
        "print(f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXilfaEIQRje",
        "outputId": "35ebac36-db4e-475f-b23a-969b024eaf90"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: data penjualan Gaikindo saat kenaikan BBM yang terjadi di masa lalu. Menurut data yang disampaikan, penjualan BBM naik malah bikin penjualan naik.\"Tahun 2003 pernah ada kenaikan bahan bakar, 2004 naik lagi harga bbmnya. Kemudian disusul tahun 2005. Namun di sepanjang 3 tahun itu kondisinya menarik. Melihat penjualan grafik 2003, 2004, 2005 itu naik, dari ke 354 (ribu) ke 534 (ribu),\" ungkap Kukuh saat diskusi virtual bersama Forum Wartawan Otomotif, Kamis (15/9/2022).\"Dalam kurun waktu itu kenaikan bahan bakar tidak berpengaruh ke penjualan kendaraan bermotor,\" jelas dia.Lebih lanjut Kukuh juga membagikan data penjualan saat BBM mengalami kenaikan pada tahun 2012 dan 2013. Pola kenaikan penjualan juga terjadi dalam kurun waktu tersebut. Pada 2012, Gaikindo mencatat penjualan mencapai 894 ribu unit, dan setahun berikutnya naik jadi 1,16 juta unit.\"Kejadian ini berulang lagi di tahun 2012, 2013, di mana ada kenaikan bahan bakar. Saat itu pun kalau kita lihat pertumbuhan ekonomi bagus di 6,2 (persen) di 2012, dan sekitar 5,78 (persen) di 2013. Dua tahun itu penjualan kendaraan bermotor juga naik walaupun ada kenaikan bahan bakar,\" terang dia.\"Kita harapkan dari data-data sejarah seperti itu, kita harapkan kenaikan kali inipun tidak berpengaruh terhadap penjualan kendaraan bermotor,\" | Label : negative (53.681%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Banyuwangi menyiapkan 342 rubuha yang akan disebar ke sejumlah wilayah dengan tingkat populasi tikus tinggi. Termasuk Kecamatan Tegaldlimo yang mendapatkan alokasi 27 rubuha. Sebelumnya, di kecamatan ini sudah terdapat 60 rubuha yang tersebar di 6 desa.\"Dengan program ini, kita harapkan kelestarian burung hantu semakin terjaga. Diiringi dengan penurunan hama tikus sehingga produksi padi dan pendapatan petani semakin meningkat,\"'\n",
        "subwords = tokenizer.encode(text)\n",
        "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
        "\n",
        "logits = model(subwords)[0]\n",
        "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
        "\n",
        "print(f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRPxqKCyO4Dk",
        "outputId": "7700fd01-9906-439e-f58a-60bbc330c88e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: Banyuwangi menyiapkan 342 rubuha yang akan disebar ke sejumlah wilayah dengan tingkat populasi tikus tinggi. Termasuk Kecamatan Tegaldlimo yang mendapatkan alokasi 27 rubuha. Sebelumnya, di kecamatan ini sudah terdapat 60 rubuha yang tersebar di 6 desa.\"Dengan program ini, kita harapkan kelestarian burung hantu semakin terjaga. Diiringi dengan penurunan hama tikus sehingga produksi padi dan pendapatan petani semakin meningkat,\" | Label : positive (97.313%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Data internal Tokopedia mencatat terjadi kenaikan jumlah transaksi kategori otomotif sebesar hampir 1,5x lipat pada semester 1 2022 dibandingkan periode sama 2021. Audio & video mobil, ban mobil, aksesori motor, alat berat dan aksesori pengendara motor pun menjadi produk kategori otomotif yang paling diminati masyarakat setahun terakhir,\" kata Head of Regional Growth Expansion Tokopedia Nafisah Wulandari dalam keterangan tertulis, Rabu (31/8/2022).Ia menuturkan, industri otomotif yang masuk ke ranah digital mendapatkan sambutan positif dari masyarakat. Hal tersebut terlihat dari data internal yang dimiliki oleh Tokopedia menyebutkan sektor otomotif tumbuh positif.Secara angka, ia menyebutkan, Tokopedia Garage juga mencatat kenaikan transaksi sebesar hampir 6x lipat pada semester 1 2022 dibandingkan periode sama 2021.'\n",
        "subwords = tokenizer.encode(text)\n",
        "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
        "\n",
        "logits = model(subwords)[0]\n",
        "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
        "\n",
        "print(f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c0CrWfQQkez",
        "outputId": "afe8eb14-366f-41b9-fd12-cf5161ab4e68"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: Data internal Tokopedia mencatat terjadi kenaikan jumlah transaksi kategori otomotif sebesar hampir 1,5x lipat pada semester 1 2022 dibandingkan periode sama 2021. Audio & video mobil, ban mobil, aksesori motor, alat berat dan aksesori pengendara motor pun menjadi produk kategori otomotif yang paling diminati masyarakat setahun terakhir,\" kata Head of Regional Growth Expansion Tokopedia Nafisah Wulandari dalam keterangan tertulis, Rabu (31/8/2022).Ia menuturkan, industri otomotif yang masuk ke ranah digital mendapatkan sambutan positif dari masyarakat. Hal tersebut terlihat dari data internal yang dimiliki oleh Tokopedia menyebutkan sektor otomotif tumbuh positif.Secara angka, ia menyebutkan, Tokopedia Garage juga mencatat kenaikan transaksi sebesar hampir 6x lipat pada semester 1 2022 dibandingkan periode sama 2021. | Label : positive (80.585%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Pemerintah mewajibkan BBM memiliki RON minimal 90 mulai 1 Januari 2023. Dengan demikian, BBM dengan kadar RON di bawah itu tak boleh lagi dijual.Saat ini masih terdapat beberapa BBM yang memiliki RON di bawah 90. Sebut saja, Premium yang dijual PT Pertamina (Persero) dengan RON 88 dan Revvo 89 yang dijual PT Vivo Energy Indonesia dengan RON 89.Corporate Secretary PT Pertamina Patra Niaga, Irto Ginting mengatakan, Premium sudah tidak lagi disalurkan di SPBU pada tahun ini.\"Premium sudah tidak disalurkan lagi di SPBU tahun 2022 ini,\" katanya kepada, seperti dikutip dari detikFinance Minggu (18/9/2022).Dia mengatakan, Pertalite merupakan BBM RON 90. Dengan demikian, pihaknya sesuai dengan kebijakan pemerintah tersebut.\"Kalau begitu kita masih sesuai dengan ketentuan itu. Karena RON terendah kita 90,\" jelasnya.Sementara, manajemen Vivo Energy Indonesia sempat buka suara terkait kelanjutan BBM Revvo 89. Vivo menjelaskan, pemerintah telah memutuskan untuk menghapus penjualan BBM beroktan rendah pada tanggal 31 Desember 2022.\"Untuk mematuhi kebijakan pemerintah, PT Vivo Energy Indonesia telah mengambil langkah‐langkah yang diperlukan untuk menghabiskan persediaan Revvo 89 kami pada akhir tahun ini,\"'\n",
        "subwords = tokenizer.encode(text)\n",
        "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
        "\n",
        "logits = model(subwords)[0]\n",
        "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
        "\n",
        "print(f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
      ],
      "metadata": {
        "id": "WVtWU1884X-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3958a88-81a6-402a-ddd7-9ae00259a4ab"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: Pemerintah mewajibkan BBM memiliki RON minimal 90 mulai 1 Januari 2023. Dengan demikian, BBM dengan kadar RON di bawah itu tak boleh lagi dijual.Saat ini masih terdapat beberapa BBM yang memiliki RON di bawah 90. Sebut saja, Premium yang dijual PT Pertamina (Persero) dengan RON 88 dan Revvo 89 yang dijual PT Vivo Energy Indonesia dengan RON 89.Corporate Secretary PT Pertamina Patra Niaga, Irto Ginting mengatakan, Premium sudah tidak lagi disalurkan di SPBU pada tahun ini.\"Premium sudah tidak disalurkan lagi di SPBU tahun 2022 ini,\" katanya kepada, seperti dikutip dari detikFinance Minggu (18/9/2022).Dia mengatakan, Pertalite merupakan BBM RON 90. Dengan demikian, pihaknya sesuai dengan kebijakan pemerintah tersebut.\"Kalau begitu kita masih sesuai dengan ketentuan itu. Karena RON terendah kita 90,\" jelasnya.Sementara, manajemen Vivo Energy Indonesia sempat buka suara terkait kelanjutan BBM Revvo 89. Vivo menjelaskan, pemerintah telah memutuskan untuk menghapus penjualan BBM beroktan rendah pada tanggal 31 Desember 2022.\"Untuk mematuhi kebijakan pemerintah, PT Vivo Energy Indonesia telah mengambil langkah‐langkah yang diperlukan untuk menghabiskan persediaan Revvo 89 kami pada akhir tahun ini,\" | Label : negative (71.412%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'komitmen bersama menghentikan semua aktivitas pelayanan jasa pariwisata di Kabupaten Manggarai Barat itu tanpa ada paksaan dari pihak manapun.Aksi itu diteken di dalam MoU atau nota kesepahaman. Dalam MoU itu itu juga disebutkan bahwa para pelaku wisata akan menerima konsekuensinya jika ada yang melanggar MoU tersebut. Para pelaku wisata itu seperti pemilik kapal wisata, pemilik penyedia jasa transportasi darat, pemilik restoran, pemilik hotel, fotografer, guide, pelaku usaha kuliner.Disamping itu juga sanksi lain adalah jika ada yang melanggar MoU itu maka pelaku wisata itu harus bersedia untuk dibakar bentuk fasilitasnya'\n",
        "subwords = tokenizer.encode(text)\n",
        "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
        "\n",
        "logits = model(subwords)[0]\n",
        "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
        "\n",
        "print(f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1heGtccbRKLf",
        "outputId": "03acd2e4-094a-45dd-cd6e-e0f24575de3e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: komitmen bersama menghentikan semua aktivitas pelayanan jasa pariwisata di Kabupaten Manggarai Barat itu tanpa ada paksaan dari pihak manapun.Aksi itu diteken di dalam MoU atau nota kesepahaman. Dalam MoU itu itu juga disebutkan bahwa para pelaku wisata akan menerima konsekuensinya jika ada yang melanggar MoU tersebut. Para pelaku wisata itu seperti pemilik kapal wisata, pemilik penyedia jasa transportasi darat, pemilik restoran, pemilik hotel, fotografer, guide, pelaku usaha kuliner.Disamping itu juga sanksi lain adalah jika ada yang melanggar MoU itu maka pelaku wisata itu harus bersedia untuk dibakar bentuk fasilitasnya | Label : negative (64.761%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Arief kemudian menyoroti isu lain terkait penyediaan air minum yang saat ini belum dapat memenuhi kebutuhan masyarakat. Dia berharap PAM Jaya dapat memberikan pasokan air mencapai 100 persen kepada masyarakat.\"Kemudian hal lain yang menjadi isu kami PAM Jaya dari sisi penyediaan air minum saat ini belum cakupannya memenuhi dari keinginan masyarakat DKI Jakarat,\" ujar Arief.Arief memastikan PAM Jaya dan Pemprov DKI Jakarta akan menambah air baku agar bisa memenuhi kebutuhan masyarakat dengan target pelayanan 100 persen pada 2030. Penambahan air baku itu melalui Sistem Pengelolaan Air Minum (SPAM).\"Ada beberapa strategi yang akan dilakukan Pam Jaya yang salah satunya pointing kita ada kemudian bagaimana menambah air baku yang kemudian bisa mencukupi kebutuhan masyarakat Jakarta. Kita mengenal dengan istilah SPAM,\" ucap Arief.\"Dari hal ini SPAM bertujuan untuk mempercepat kebutuhan dasar masyarakat di Provinsi DKI Jakarta adalah targetnya pelayanan 100 persen di tahun 2030,\" imbuhnya'\n",
        "subwords = tokenizer.encode(text)\n",
        "subwords = torch.LongTensor(subwords).view(1, -1).to(model.device)\n",
        "\n",
        "logits = model(subwords)[0]\n",
        "label = torch.topk(logits, k=1, dim=-1)[1].squeeze().item()\n",
        "\n",
        "print(f'Text: {text} | Label : {i2w[label]} ({F.softmax(logits, dim=-1).squeeze()[label] * 100:.3f}%)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE4UWn7rRVXI",
        "outputId": "51c977cd-c075-4fe5-f2d0-e271d8b2f4bf"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: Arief kemudian menyoroti isu lain terkait penyediaan air minum yang saat ini belum dapat memenuhi kebutuhan masyarakat. Dia berharap PAM Jaya dapat memberikan pasokan air mencapai 100 persen kepada masyarakat.\"Kemudian hal lain yang menjadi isu kami PAM Jaya dari sisi penyediaan air minum saat ini belum cakupannya memenuhi dari keinginan masyarakat DKI Jakarat,\" ujar Arief.Arief memastikan PAM Jaya dan Pemprov DKI Jakarta akan menambah air baku agar bisa memenuhi kebutuhan masyarakat dengan target pelayanan 100 persen pada 2030. Penambahan air baku itu melalui Sistem Pengelolaan Air Minum (SPAM).\"Ada beberapa strategi yang akan dilakukan Pam Jaya yang salah satunya pointing kita ada kemudian bagaimana menambah air baku yang kemudian bisa mencukupi kebutuhan masyarakat Jakarta. Kita mengenal dengan istilah SPAM,\" ucap Arief.\"Dari hal ini SPAM bertujuan untuk mempercepat kebutuhan dasar masyarakat di Provinsi DKI Jakarta adalah targetnya pelayanan 100 persen di tahun 2030,\" imbuhnya | Label : positive (67.852%)\n"
          ]
        }
      ]
    }
  ]
}